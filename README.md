# Loan Approval Prediction ‚Äì End-to-End ML Pipeline

This project builds a **complete credit-risk prediction system** for **FinTrust**, a digital lending company, using a simple **three-script structure**:

1. **Data Exploration & Analysis** ‚Äì `model.py`
2. **Data Preprocessing** ‚Äì `data_cleaner.py`
3. **Model Training & Evaluation** ‚Äì `main.py`

The final output is a **Logistic Regression model** capable of predicting whether a loan application will be **Approved** or **Rejected**.

---

## üìÇ Project Structure

```
loan-approval/
‚îÇ
‚îú‚îÄ‚îÄ loan_data.csv              # Raw dataset
‚îú‚îÄ‚îÄ model.py                   # Part 1: Data exploration & EDA
‚îú‚îÄ‚îÄ data_cleaner.py            # Part 2: Data cleaning & preprocessing
‚îú‚îÄ‚îÄ main.py                    # Part 3: Logistic Regression training & evaluation
‚îî‚îÄ‚îÄ README.md
```

---

## 1Ô∏è‚É£ model.py ‚Äì Data Exploration and Analysis

Goal: **Understand the dataset before modeling**

Key actions inside `model.py`:

* Load dataset with `pandas.read_csv`
* Display shape and column names
* Check data types to separate numerical & categorical features
* Identify missing values
* Generate summary statistics using `.describe()`
* Perform simple visualizations (histograms, boxplots, correlations)

Insights:

* Found missing values in some columns (e.g., `Gender`, `LoanAmount`).
* Observed class imbalance in `Loan_Status`.

---

## 2Ô∏è‚É£ data\_cleaner.py ‚Äì Preprocessing

Goal: **Clean and prepare data for modeling**

Main steps:

* **Handle Missing Values**

  * Numerical columns: imputed with mean/median
  * Categorical columns: filled with mode
* **Encode Categorical Variables** using `LabelEncoder`
* **Scale Numerical Features** using `MinMaxScaler`
* Output a cleaned, ready-to-train dataset and save transformation tools (`encoder.pkl`, `scaler.pkl`).

---

## 3Ô∏è‚É£ main.py ‚Äì Model Training & Evaluation

Goal: **Train and evaluate the predictive model**

Operations in `main.py`:

* Load the preprocessed dataset from `data_cleaner.py`
* Train a `sklearn.linear_model.LogisticRegression` model
* Evaluate with:

  * Accuracy
  * Confusion Matrix
  * Precision, Recall, F1-Score (optional)
* Save the trained model as `logistic_model.pkl` for future predictions.

---

## üöÄ Quick Start

### Prerequisites

* Python 3.9+
* Install dependencies:

```bash
pip install -r requirements.txt
```

### Run the Full Pipeline

1. **Explore Data**

   ```bash
   python model.py
   ```

2. **Clean & Preprocess Data**

   ```bash
   python data_cleaner.py
   ```

3. **Train & Evaluate Model**

   ```bash
   python main.py
   ```

This produces:

* `encoder.pkl` and `scaler.pkl` for consistent transformations
* `logistic_model.pkl` trained model file

---

## üß© Example Prediction

```python
import joblib
import pandas as pd

# Load saved objects
scaler = joblib.load("scaler.pkl")
encoder = joblib.load("encoder.pkl")
model  = joblib.load("logistic_model.pkl")

# New applicant data as DataFrame
new_applicant = pd.DataFrame({
    "Gender": ["Male"],
    "Married": ["Yes"],
    "ApplicantIncome": [5000],
    "LoanAmount": [150],
    # ... other features ...
})

# Apply preprocessing (encoding & scaling) before prediction
new_applicant_encoded = encoder.transform(new_applicant)
new_applicant_scaled  = scaler.transform(new_applicant_encoded)

# Predict
prediction = model.predict(new_applicant_scaled)
print("Loan Status:", "Approved" if prediction[0] == 1 else "Rejected")
```

---

## üìà Future Improvements

* Hyperparameter tuning with GridSearchCV or RandomizedSearchCV
* Handle class imbalance using SMOTE or class weights
* Experiment with other classifiers such as Random Forest or XGBoost

---

## üõ†Ô∏è Tech Stack

* **Python 3**
* **Pandas, NumPy, Matplotlib, Seaborn**
* **Scikit-learn**

---

## ‚úçÔ∏è Author

**divs-spec**
Contributions & pull requests are welcome!
